---
title: 'Final Project: Food Inspection Failures in Chicago'
author: "Sabir Nazarov, William Friedrichs"
date: "12/1/2021"
output: 
  html_document: 
    self_contained: yes
    code_folding: hide
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---
A short PechaKucha style presentation of the application can be viewed here: 
[![CLICK HERE](CoverSlide.jpg)](https://youtu.be/qqpEqwANbVE)

# 1. Introduction
On July 1st, 2016, Chicago Department of Public Health (CDPH) identified an E. coli outbreak linked to a restaurant in Bridgeport neighborhood of Chicago.  Within days, the number of cases swelled from initially report 25 cases to 65.  The outbreak resulted in stunning 20 hospitalizations.  By the time, the dust settled, over 100 people, including 40 food handlers from the restaurant, suffered illness.  The outbreak, one of the worst in the cities recent history, exposed the critical work conducted by the city's restaurant safety inspectors.  Their report of the July 1st inspection identified <strong>critical failure</strong> in revealing "improper temperatures for several food items".  The actions mitigated the effect of an outbreak which could have been much worse, had it not been identified promptly. 

This application would help the city avoid these kinds of incidents by forecasting the number of restaurant inspection failures in Chicago for a given year, giving the city a better idea of the total number of inspections needed and informing its distribution of health inspectors across the city.
x
The City of Chicago employs approximately 3 dozen restaurant food inspectors.  With over 15,000 inspections taking place in Chicago in 2019 alone, the sheer volume of this task necessitates prediction-aided planning. Our application, presented here, allows for greater precision in anticipating possible inspection failures using machine-learning algorithms.  In adopting our application, the city of Chicago shortens the feedback loop in identification of critical failures, thus preventing future outbreak.  In addition to improving public health outcomes, our application improves the allocation of the limited number of inspectors yielding greater efficiency.  The built-in scheduling algorithm prioritizes inspections in the high risk areas with  mechanisms for revising inspector schedules based on latest available data.  We know that certain risk-factors can significantly increase chance of a failure--we incorporate these risks real-time.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
	message = FALSE,
	warning = FALSE,
	include = TRUE,
	cache = FALSE,
	echo=TRUE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

```

```{r , results = FALSE}

# Create a map containing boundary of Chicago.
chicagoBoundary <- 
  st_read(file.path(root.dir,"/Chapter5/chicagoBoundary.geojson")) %>%
  st_transform('ESRI:102271') 

# Create a fishnet containing 500 by 500 foot squares over the boundary of Chicago.
fishnet <- 
  st_make_grid(chicagoBoundary,
               cellsize = 500, 
               square = TRUE) %>%
  .[chicagoBoundary] %>%            # <- MDH Added
  st_sf() %>%
  mutate(uniqueID = rownames(.))

## Neighborhoods to use 
neighborhoods <- 
  st_read("https://raw.githubusercontent.com/blackmad/neighborhoods/master/chicago.geojson") %>%
  st_transform(st_crs(fishnet))

Food <-
  read.socrata("https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5") 

FoodInspectAll <- Food %>%
    mutate(year = substr(inspection_date,1,4)) %>% 
    filter(year == "2018") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Food_Inspect_All")


```


# 2. Exploratory Analysis

  For anyone wishing to replicate this analysis, we emphasize the importance of visually understanding the spatial distribution of general restaurant inspection failure counts. It is also important to know the spatial layout of independent variables—the factors we use to predict Chicago’s inspection failures. This section provides an overview of our exploratory analysis.
	
  First, we take a look at Chicago’s 2018 inspection failures. There are tens of thousands of inspections for 2018, with just under 20% of them being failed inspections. In our case example, we predict restaurant failures for Chicago in 2019 using 2018 inspection data, so in our exploratory analysis, we consider data from 2018. A simple plot of restaurant inspection failures by location in Chicago is displayed below.
		
```{r fig.width=6, fig.height=4}
FoodInspect <- Food %>%
    mutate(year = substr(inspection_date,1,4)) %>% 
    filter(year == "2018") %>%
    filter(results=="Fail") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Food_Inspect")

ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = FoodInspect, colour="red", size=0.1, show.legend = "point") +
  labs(title= "Failed Food Inspections, Chicago - 2018") +
  mapTheme(title_size = 14)


```

  Several clusters immediately stand out. The darkest cluster, to the east, is the Loop. There are also higher numbers of failed inspections along the North Shore, and to the west in Lawndale. The spatial clustering of failed inspections is a good sign that spatial analysis is appropriate in predicting failed inspections. 
  
Perhaps the most important spatial factors in predicting inspection failures is restaurant locations. There cannot be a failure without a restaurant to be inspected in the first place, after all. When examining all restaurant inspection locations, this time, we will map density as a layer rather than plotting each establishment individually. This avoids situations where data for restaurants in close proximity could be obscured due to overlapping, which would be more of a problem given the size of the all-restaurants dataset. Displayed below are side-by-side density maps of all restaurants logged for inspection in 2018 and restaurant inspection failures for that year.

```{r fig.width=6, fig.height=4}
grid.arrange(ncol=2,

ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "grey80") +
  stat_density2d(data = data.frame(st_coordinates(FoodInspectAll)),
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Food Inspections Density") +
  mapTheme(title_size = 14) + theme(legend.position = "none"),

ggplot() + 
  geom_sf(data = chicagoBoundary, fill = "grey80") +
  stat_density2d(data = data.frame(st_coordinates(FoodInspect)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Failed Food Inspection Density") +
  mapTheme(title_size = 14) + theme(legend.position = "none")
)
```

  Brighter green represents higher density on the maps above. The maps are very similar, which is a testament to the importance of restaurant locations as a predicting factor. Just by the visual comparison between the graphs, however, there seem to be some areas with higher concentrations of failures in comparison to total inspection numbers (specifically along the North Shore, and in in Lawndale). These patterns support the use of this application, because the differences in the maps show that assigning inspectors purely based on restaurant density would not be the optimal way for the Chicago Health Department to assign its resources. Some areas are more likely have inspection-failing restaurants than others despite similar counts of restaurants. Because failures add an additional inspection, this report's predictive tool looks to determine where failures are likely to occur.
  
  This tool aims to take data from one year and predict failed food inspections for the following year, so it is useful to compare the locations of two annual sets of food inspections side-by-side. The maps below illustrate locations of failed inspections in 2017 and 2018.

```{r fig.width=6, fig.height=4}
## Get 2017 data
FoodInspect17 <-
  read.socrata("https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5") %>%
    mutate(year = substr(inspection_date,1,4)) %>% filter(year == "2017") %>%
    filter(results=="Fail") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Food_Inspect")

grid.arrange(ncol=2,
             ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = FoodInspect17, colour="red", size=0.1, show.legend = "point") +
  labs(title= "2017 Failed Food Inspections") +
  mapTheme(title_size = 14),
  
  ggplot() + 
  geom_sf(data = chicagoBoundary) +
  geom_sf(data = FoodInspect, colour="red", size=0.1, show.legend = "point") +
  labs(title= "2018 Failed Food Inspections") +
  mapTheme(title_size = 14)
)
```

Failed inspections for 2017 and 2018 look very similar. This supports the notion that one year's failed inspections can be used to predict those of the next year. Some of the differences can be attributed to the fact that a slightly different set of restaurants are inspected each year. For example, food inspections in 2019 covered 387 additional restaurants compared to 2018. 

# 3. Our Spatial Process: the Fishnet

An ideal spatial process for our model must take into account factors that are relevant at a local level, and that factors affecting one restaurant are very likely to affect those nearby. Additionally, rather than predicting outcomes of individual scheduled inspections on a restaurant by restaurant basis, a spatial process should be used that is compatible with the fact that new establishments are added to the database on a yearly basis.

Predicting on a <strong>fishnet grid</strong> such that Chicago is divided into equally sized square cells accomplishes this. This model uses the previous year's inspections and other risk factors to generate a prediction of the number of failed inspections in each cell. The map below displays the actual count of 2018 restaurant failures per cell on the grid. For the purposes of this model, each cell will be 500 square meters, area equivalent to about 2.5 Chicago city blocks. 

```{r}
## Add a value of 1 for each failure, sum them with aggregate
inspect_net <- 
  dplyr::select(FoodInspect) %>% 
  mutate(countInspect = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countInspect = replace_na(countInspect, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

# Plot the fishnet displaying the count of inspection failures
ggplot() +
  geom_sf(data = inspect_net, aes(fill = countInspect), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of Inspection Failures for the Fishnet") +
  mapTheme()

# Create a histogram for exploration of expected prediction distribution
HistogramInspect <-
  inspect_net %>%
    group_by(uniqueID) %>%
    summarize(countInspect_sum = sum(countInspect, na.rm = T),
              countInspect_mean = mean(countInspect, na.rm = T)) %>%
  ungroup()

# plot histogram of failures
HistogramInspect %>%
  ggplot(aes(countInspect_sum)) +
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    scale_x_continuous(breaks = seq(0, 100, by = 5)) +
    labs(title="Distribution of Failed Inspection Counts", subtitle = "Chicago, IL",
         x="Number of Failed Inspection Counts", y="Number of Cells")
```

The histogram above illustrates the distribution of cells according to their actual number of failed restaurants for 2018. Of the 2500 cells that comprise Chicago's area, just over half recorded no failed inspections. The vast majority of cells that did have failed inspections had less than 10, though a few individual cells had 30 or more. When our 2018 model is used to predict failures by fishnet cell for 2019, predictions will have a similar distribution. Our spatial process should produce a similar result, as its estimates will reflect the clustered nature of restaurant failures in Chicago when it makes its predictions.

# 4. Our Modeling Approach: Spatial Risk Factors

As stated in the introduction, the goal of the model itself is to spatially predict failed inspections such that an estimate of the total number of inspections can be used to more efficiently allocate inspectors throughout Chicago. To predict inspection failures for a target year, our model uses a generalized linear model. Specifically, our model creates a function which, for each cell in the fishnet, takes a set of dependent variables and returns a predicted number of restaurant inspection failures. The actual predictions for each cell that are used as forecasts of failed inspections for a given year are outputs of k-fold validation of data from the prior year. This will be explored in more detail in the next section, but the basic idea is that the predictions created by k-fold cross validation of one year's risk factors data and actual failure counts are used as predictions for the ensuing year. 

### Risk Factor Descriptions

Our approach is to make this process successful by using a set of independent variables whose spatial distributions collectively do well to predict restaurant inspection failures. Each independent variable or "risk factor" is explored in more detail in the subsections below.

#### Inspection Locations and 3NN of Inspection Failure Locations

_Inspection Locations_ - As described in the previous section, inspection locations are vital predictors of the next year's failure locations. In order for a restaurant to fail an inspection, the inspection must take place at a location, and chances are that location is contained within the set of the previous year's inspection locations. Like the rest of the risk factors, inspection locations are used in their fishnet form. 

```{r, results = FALSE}
# Food establishment locations, 2018
foodInspectLocations <-
  read.socrata("https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5") %>%
    mutate(year = substr(inspection_date,1,4)) %>% filter(year == "2018") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    distinct() %>%
    mutate(Legend = "Food_Inspect_Locations") 
```

_Inspection Failure Locations (3NN)_ - Inspection failure locations cannot be added as a risk factor outright, as k-folds validation in the next section seeks to optimize this exact variable. If inspection failure locations were included as is, k-folds validation would heavily overfit its predictions based on this variable, giving minimal consideration to other variables. The model would be more "accurate" in replicating the locations of inspection failures, but less generalizeable to the following year and less useful as a predictive tool. Instead, an independent variable is introduced reflecting the mean distance to the three nearest inspection failure points for any point in Chicago. Averaged by fishnet cell, this results in a factor that can help predict inspection failure locations without causing the cross validation to overfit. 

```{r, results = FALSE}
# Food inspection failures, 2018
# 3NN to be performed on this risk factor later
foodInspectFail <-
  read.socrata("https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5") %>%
    mutate(year = substr(inspection_date,1,4)) %>% filter(year == "2018") %>%
    filter(results=="Fail") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Food_Inspect_Fail")
```

#### Six Risk Factors from the Chicago Open Data Portal

The following risk factors are considered to be potential predictors of Failed Food Inspections, and are accessed from the Chicago Open Data Portal. All five of these risk factors use Three Nearest Neighbor (3NN) analysis. While it would not break the model's generalizability to use these data in their raw form, 3NN versions of these risk factors tended to perform slightly better in the model. 

_Rodent Complaints (3NN)_ - This variable records location-based 311 service requests for rodent baiting over a year. There were 39,023 instances in 2018.

```{r, results = FALSE}
rodentBait <- 
  read.socrata("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Rodent-Baiting-Historic   al/97t6-zrhs") %>%
    mutate(year = substr(creation_date,1,4)) %>% filter(year == "2018") %>%
    dplyr::select(Y = latitude, X = longitude) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Rodent_Bait")
```

_Sanitation (3NN)_ - This variable records location-based 311 service associated with sanitation code complaints. There were 3,316 instances in 2018. 

```{r, results = FALSE}
sanitation311 <-
  read.socrata(paste0("https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Sanitation-Code-Complaints-Hi/me59-5fac")) %>%
  mutate(year = substr(creation_date,1,4)) %>%
  filter(year == "2018") %>%
  filter(what_is_the_nature_of_this_code_violation_ %in%
  c("Garbage in Yard","Garbage in Alley","Dumpster not being emptied", "Overflowing carts", "Construction Site Cleanliness/Fence", "Standing water")) %>%
  dplyr::select(Y = latitude, X = longitude) %>%
  na.omit() %>%
  st_as_sf(coords = c("X","Y"), crs=4326, agr="constant") %>%
  st_transform(st_crs(fishnet)) %>%
  mutate(Legend = "Sanitation_311")
```

_Ordinance Violation (3NN)_ - This variable refers to reported Department of Buildings ordinance violations in Chicago. In 2018, there were reports of 43,243 of these.

```{r, results = FALSE}
ordinanceViolation <- 
  read.socrata("https://data.cityofchicago.org/Administration-Finance/Ordinance-Violations-Buildings-/awqx-tuwv") %>%
    mutate(year = substr(VIOLATION.DATE,1,4)) %>% filter(year == "2018") %>%
    dplyr::select(Y = LATITUDE, X = LONGITUDE) %>%
    na.omit() %>%
    st_as_sf(coords = c("X", "Y"), crs = 4326, agr = "constant") %>%
    st_transform(st_crs(fishnet)) %>%
    mutate(Legend = "Ordinance_Violations")
```

_Graffiti (3NN)_ - This records all 311 service requests for the removal of graffiti in Chicago. There were 55,873 of these requests in Chicago in 2018.

```{r, results = FALSE}
graffiti <-
  read.socrata(paste0("https://data.cityofchicago.org/Service",
  "-Requests/311-Service-Requests-Graffiti-Removal-Historical/",
  "hec5-y4x5")) %>%
  mutate(year = substr(creation_date,1,4)) %>%
  filter(year == "2018") %>%
  filter(where_is_the_graffiti_located_ %in%
  c("Front","Rear","Side")) %>%
  dplyr::select(Y = latitude, X = longitude) %>%
  na.omit() %>%
  st_as_sf(coords = c("X","Y"), crs=4326, agr="constant") %>%
  st_transform(st_crs(fishnet)) %>%
  mutate(Legend = "Graffiti")
```

_Liquor Retail (3NN)_ - This variable derives the locations of liquor stores from the Chicago Open Data Portal Database business license data.

```{r, results = FALSE}
liquorRetail <-
  read.socrata(paste0("https://data.cityofchicago.org/resource/",
  "nrmj-3kcf.json")) %>%
  filter(business_activity ==
  "Retail Sales of Packaged Liquor") %>%
  dplyr::select(Y = latitude, X = longitude) %>%
  na.omit() %>%
  st_as_sf(coords = c("X","Y"), crs=4326, agr="constant") %>%
  st_transform(st_crs(fishnet)) %>%
  mutate(Legend = "Liquor_Retail")
```

The plot below displays maps of each of the previously listed risk factors. Note that the lighter colors correspond to cells farther from these factors, meaning that in this case, cells with darker colors have a higher likelihood of failed inspections being predicted in them.  

```{r}
# Create a binded set of nets with the variables of interest collected thus far
vars_net <- rbind(rodentBait, sanitation311, ordinanceViolation, graffiti, liquorRetail, foodInspectFail, foodInspectLocations)   %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  summarize(count = n()) %>%
  full_join(fishnet, by = "uniqueID") %>%
  spread(Legend, count, fill=0) %>%
  st_sf() %>%
  dplyr::select(-`<NA>`) %>%
  na.omit() %>%
  ungroup()

# Create long bersion
vars_net.long <-
  gather(vars_net, Variable, value, -geometry, -uniqueID)

# Create list
vars <- unique(vars_net.long$Variable)
  mapList1 <- list()

# Convenience to reduce length of function names.
st_c    <- st_coordinates
st_coid <- st_centroid

## create NN from rodent bait
vars_net <- vars_net %>%
    mutate(rodent_Bait.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(rodentBait),
                                           k = 3))

## create NN from sanitation 311
vars_net <- vars_net %>%
    mutate(sanitation_311.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(sanitation311),
                                           k = 3))

## create NN from ordinance violations
vars_net <- vars_net %>%
    mutate(ordinance_Violation.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(ordinanceViolation),
                                           k = 3))

## create NN from graffiti
vars_net <- vars_net %>%
    mutate(graffiti.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(graffiti),
                                           k = 3))

## create NN from liquorRetail
vars_net <- vars_net %>%
    mutate(liquor_Retail.nn = nn_function(st_c(st_coid(vars_net)), 
                                           st_c(liquorRetail),
                                           k = 3))

vars_net.long.nn <-
  dplyr::select(vars_net, ends_with(".nn")) %>%
  gather(Variable, value, -geometry)
  vars <- unique(vars_net.long.nn$Variable)

mapList2 <- list()

for(i in vars){
  mapList2[[i]] <-
  ggplot() +
  geom_sf(data = filter(vars_net.long.nn, Variable == i),
  aes(fill=value), colour=NA) +
  scale_fill_viridis(name="") +
  labs(title=i) +
mapTheme()}

do.call(grid.arrange,c(mapList2, ncol = 3,
top = "Nearest Neighbor risk Factors by Fishnet"))

# create NN from food_Inspect_Fail
# This comes after the others as to not appear in the group of plots
vars_net <- vars_net %>%
    mutate(food_Inspect_Fail.nn = nn_function(st_c(st_coid(vars_net)),
                                           st_c(foodInspectFail),
                                           k = 3))



# Gather all .nn vars as vars_net.long.nn
vars_net.long.nn <- 
  dplyr::select(vars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

```

#### Additional Risk Factors

_Distance to The Loop_ - Another factor considered by the model is distance from Chicago's downtown area called "The Loop." In the Exploratory Analysis section, it was noted that The Loop has a high number of failed inspections. This factor looks to operationalize that observation by creating a risk factor. Distance to The Loop is plotted below to the left.

_Significant Hot Spot (3NN)_ - Also considered is the mean distance to each cell's three nearest "hot spot" neighbors. A cell is marked as a hot spot if it has a higher failure count higher than it would have in at least 99% of spatially random distributions of inspection failures. This is generated via a three nearest neighbors analysis of a grid of hot spot cells, and is plotted below to the right.

_Is Significant Hot Spot_ - The binary variable mapping whether a given cell is a hot spot or not is also included.

```{r}
#Distance to Loop to be used later
loopPoint <-
  filter(neighborhoods, name == "Loop") %>%
  st_centroid()
  vars_net$loopDistance =
  st_distance(st_centroid(vars_net), loopPoint) %>%
  as.numeric()

## important to drop the geometry from joining features
final_net <-
  left_join(inspect_net, st_drop_geometry(vars_net), by="uniqueID") 

## generates warnings from PROJ issues
## {spdep} to make polygon to neighborhoods... 
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
## ... and neighborhoods to list of weigths
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)
# print(final_net.weights, zero.policy=TRUE)

## see ?localmoran
local_morans <- localmoran(final_net$countInspect, final_net.weights, zero.policy=TRUE) %>% 
  as.data.frame()

# join local Moran's I results to fishnet
final_net.localMorans <- 
  cbind(local_morans, as.data.frame(final_net)) %>% 
  st_sf() %>%
  dplyr::select(countInspect = countInspect, 
                Local_Morans_I = Ii, 
                P_Value = `Pr(z != E(Ii))`) %>%
  mutate(Significant_Hotspots = ifelse(P_Value <= 0.001, 1, 0)) %>%
  gather(Variable, Value, -geometry)


# generates warning from NN
final_net <- final_net %>% 
  mutate(Inspect.isSig = 
           ifelse(local_morans[,5] <= 0.001, 1, 0)) %>%
  mutate(Inspect.isSig.dist = 
           nn_function(st_c(st_coid(final_net)),
                       st_c(st_coid(filter(final_net, 
                                           Inspect.isSig == 1))), 
                       k = 1))
grid.arrange(ncol=2,
  ggplot() +
    geom_sf(data = vars_net, aes(fill=loopDistance), colour=NA) +
    scale_fill_viridis(name="loopDistance") +
    labs(title="Distance to The Loop") +
    mapTheme(),
  ggplot() +
    geom_sf(data = final_net, aes(fill=Inspect.isSig.dist), colour=NA) +
    scale_fill_viridis(name="Inspect.isSig.dist") +
    labs(title="NN Distance to Significant \nFailed Inspect Clusters") +
    mapTheme()
)
```


### Risk Factor Correlations

As a part of our modeling approach, we analyzed individual linear relationships between 2018 risk factors and 2018 inspection failures across Chicago's fishnet cells. The results of this analysis are displayed in the plots below, with the r-value of each relationship (1.0 corresponding to the strongest positive correlation, 0.0 corresponding to no correlation, and -1.0 corresponding to the strongest negative correlation) displayed in the upper-left corner of each plot.

```{r, fig.width=10, fig.height=20}
correlation.long <-
  st_drop_geometry(final_net) %>%
  dplyr::select(-uniqueID, -cvID, -Sanitation_311, -Ordinance_Violations, -Graffiti, -Liquor_Retail, -Rodent_Bait, -Food_Inspect_Fail) %>%
  gather(Variable, Value, -countInspect)

# colnames(final_net)

# , foodInspectLocations, -Inspect.isSig,-name,

correlation.cor <-
  correlation.long %>%
  group_by(Variable) %>%
  summarize(correlation = cor(Value, countInspect, use = "complete.obs"))

ggplot(correlation.long, aes(Value, countInspect)) +
  geom_point(size = 0.1) +
  geom_text(data = correlation.cor,
  aes(label = paste("r =", round(correlation, 2))),
  x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
geom_smooth(method = "lm", se = FALSE, colour = "black") +
facet_wrap(~Variable, ncol = 2, scales = "free") +
labs(title = "Failed inspection count as a function of risk factors") +
plotTheme()

# Join neighborhood data by attaching centroids of fishnets to a polygon of neighborhoods. 

# This will be useful later
final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(neighborhoods, name), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() %>%
  na.omit()
```

The basic results of these analyses confirm our expectations. _Inspection Locations_ has the most significant linear relationship with inspection failure locations. _Is Significant Hot Spot_ also stood out, the binary version markedly more correlated than _Significant Hot Spot (3NN)_. _Distance to The Loop_ had a negative correlation with inspection failures, as expected. _Inspection Failure Locations (3NN)_, in addition to the five other 3NN risk factors from the Chicago Data Portal, had slight negative correlations with inspection failures. At a glance, these relationships look more logarithmic than linear. Surprisingly, log versions of these variables did not provide for a more robust model. Despite experimentation with logarithmic feature engineering, _Inspection Failure Locations (3NN)_ and the other 3NN Chicago Data Portal risk factors are included in their original forms in the final version of the model. 

### Local Moran's I results

The grid map below shows the following four elements:

1) _CountInspect_: Count of failed inspections in Chicago

2) _Local_Morans_I_: Dispersal or clustering of failed inspections relative to adjacent neighborhoods

3) _P-value_: Statistical significance of the relationship where exceptionally low

4) _Significant_Hotspots_: Major clusters of failed inspections in Chicago at 99% significance level

```{r}
## This is just for plotting
vars <- unique(final_net.localMorans$Variable)
varList2 <- list()

for(i in vars){
  varList2[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme(title_size = 14) + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList2, ncol = 4, top = "Local Morans I statistics, Inspect"))
```

These four elements clearly indicate spatial patterns in the failed inspections data. This supports the use of a fishnet-based model of prediction. It also supports the decision to take a spatial approach in selecting risk factors - if spatial relationships are key to understanding failed inspections, they are likely key to predicting failed inspections too.

# 5. Modeling with Cross Validation

As briefly outlined earlier, k-fold validation provides not only a measure of the model’s performance - it creates the actual predictions that will be used to forecast failed inspections. For a given cell, k-fold validation uses the rest of the cells as a training set to produce an individualized model that predicts only for that single cell. This process is carried out for every cell, the result is a predicted value for each one. These predictions are used to forecast the number of failures per cell in the following year.

K-fold was not the only kind of validation considered as a part of this project. ‘Leave-one-group-out’ cross-validation (LOGO-CV) was also considered. LOGO CV considers groups of data (in this case, Chicago’s neighborhoods), and trains the whole model on every possible combination of groups such that one group is always missing from the analysis. This may help when one group has a unique relationship to the dependent variable.  
Two versions of each cross-validation method were undertaken, each using a different set of independent variables. The first, more limited set includes only the food inspection failures, food inspection locations, and the five factors from Chicago's open data website. The second set of independent variables for each cross-validation method includes all of the previously listed risk factors. In total, four variations of the model are generated.

1) _Random k-fold CV: Limited Set_

2) _Random k-fold CV: All Risk Factors_

3) _Spatial LOGO-CV: Limited Set_

4) _Spatial LOGO-CV: All Risk Factors_

```{r, results='hide'}

# necessary workaround for hardcoded "countBurglaries" 
# redefine function
remove(crossValidate)
crossValidate <- function(dataset, id, dependentVariable, indVariables) {

 allPredictions <- data.frame()
 cvID_list <- unique(dataset[[id]])

 for (i in cvID_list) {
 
  thisFold <- i
  #cat("This hold out fold is", thisFold, "\n")
 
  fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>%
   dplyr::select(id, geometry, indVariables, dependentVariable)
  fold.test <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>%
   dplyr::select(id, geometry, indVariables, dependentVariable)
 
  regression <-
    glm(paste0(dependentVariable,"~."), family = "poisson",
     data = fold.train %>%
      dplyr::select(-geometry, -id))
  thisPrediction <-
   mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
 
  allPredictions <-
   rbind(allPredictions, thisPrediction)
 
 }
 return(st_sf(allPredictions))
}

# View(crossValidate)

## define independent variables
reg.ss.vars <- c("rodent_Bait.nn", "sanitation_311.nn","ordinance_Violation.nn", "graffiti.nn", "liquor_Retail.nn", "food_Inspect_Fail.nn", "Food_Inspect_Locations", "Inspect.isSig", "Inspect.isSig.dist", "loopDistance")

## define independent variables with spatial features
reg.vars <-
c("rodent_Bait.nn", "sanitation_311.nn","ordinance_Violation.nn", "graffiti.nn", "liquor_Retail.nn", "food_Inspect_Fail.nn", "Food_Inspect_Locations")

## RUN REGRESSIONS
reg.ss.spatialCV <- crossValidate(
  dataset = dplyr::rename(final_net, countFailures = countInspect),
  id = "name",
  dependentVariable = "countFailures",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = name, countFailures, Prediction, geometry)


reg.cv <- crossValidate(
  dataset = dplyr::rename(final_net, countFailures = countInspect),
  id = "cvID",
  dependentVariable = "countFailures",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countFailures, Prediction, geometry)


reg.ss.cv <- crossValidate(
  dataset = dplyr::rename(final_net, countFailures = countInspect),
  id = "cvID",
  dependentVariable = "countFailures",
  indVariables = reg.ss.vars) %>%
  dplyr::select(cvID = cvID, countFailures, Prediction, geometry)


reg.spatialCV <- crossValidate(
  dataset = dplyr::rename(final_net, countFailures = countInspect),
  id = "name",
  dependentVariable = "countFailures",
  indVariables = reg.vars) %>%
  dplyr::select(cvID = name, countFailures, Prediction, geometry)

reg.summary <-rbind(
  mutate(reg.cv,
  Error = Prediction - countFailures,
  Regression = "Random k-fold CV: Limited Set"),

  mutate(reg.ss.cv,
  Error = Prediction - countFailures,
  Regression = "Random k-fold CV: All Risk Factors"),

  mutate(reg.spatialCV,
  Error = Prediction - countFailures,
  Regression = "Spatial LOGO-CV: Limited Set"),

  mutate(reg.ss.spatialCV,
  Error = Prediction - countFailures,
  Regression = "Spatial LOGO-CV: All Risk Factors")) %>%
st_sf()

# calculate errors by NEIGHBORHOOD
error_by_reg_and_fold <-
  reg.summary %>%
  group_by(Regression, cvID) %>%
    summarize(Mean_Error = mean(Prediction - countFailures, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  arrange(desc(MAE))

# error_by_reg_and_fold %>%
#   arrange(MAE)
```

### Measuring Model Accuracy and Generalizability

For our model, we wanted to adopt the version of these four models which, using 2018 data, could make the most accurate and generalizable predictions of 2018 failure counts. A model's ability to predict for its own year in an *accurate* and *generalizable* way points to effectiveness in consistently providing well-grounded predictions for the following year.

A model's accuracy can be assessed with Mean Absolute Error (MAE). The MAE of a model measures the average difference between true value and predicted value across each data point (for the purposes of these model variations, each fishnet cell). A model's MAE is an indicator of its accuracy. Generalizability can also be analyzed by considering MAE across different portions of a dataset. Even if overall MAE is low, there may be portions of the dataset where predictions perform disproportionately poorly. 

To compare model generalizability, The distributions of MAE across Chicago neighborhood are displayed for each of the four model variations. Below, mean neighborhood MAE and the size of a standard deviation are also displayed.

```{r}
## plot histogram of OOF (out of fold) errors
error_by_reg_and_fold %>%
  ggplot(aes(MAE)) +
  geom_histogram(bins = 30, colour="black", fill="#FDE725FF") +
  facet_wrap(~Regression) +
  geom_vline(xintercept = 0) + scale_x_continuous(
  breaks = seq(0, 8, by = 1)) +
  labs(title="Distribution of MAE",
  subtitle = "k-fold cross-validation vs. LOGO-CV",
  x="Mean Absolute Error", y="Count") +
plotTheme()

## Errors by Model
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>%
  summarize(Mean_MAE = round(mean(MAE), 2),
  SD_MAE = round(sd(MAE), 2)) %>%
  kable() %>%
  kable_styling("striped", full_width = F) %>%
  row_spec(2, color = "black", background = "#FDE725FF") %>%
  row_spec(4, color = "black", background = "#FDE725FF")
```

Based on the mean and standard deviations of the MAE distributions, _Random k-fold CV: All Risk Factors_ is the most accurate and generalizable model. There are no neighborhoods in this model that produce a mean of more than one error, and compared with the other model variations, a higher number of neighborhoods produce no error at all. This is the model variation we select to predict annual inspection failures.

# 6. Model Usefulness

The model and its capability to predict Chicago food inspection failures is useful to a variety of municipal agencies and officials. This is because it allows for a data-driven, cost-effective distribution of the city's 36 food inspectors. Failed inspections require follow-up inspections, so by forecasting the distribution of failures, cities and their employees can make a better determination of how many total inspections will be necessary in a given year. 

The plot below illustrates predictions generated for the year 2019. For each cell in the fishnet, a value is generated to forecast the number of failures that will be logged over the course of the year. The value is not a whole number - it is designed to give as much information as possible to its user rather to produce a discrete prediction for each cell. This gives the user a sharper and more specific understanding of the tool's results.

```{r}
ggplot() + 
  geom_sf(data = reg.ss.cv, aes(fill = Prediction), size=0.1, show.legend = "point") +
  scale_fill_viridis(name="Prediction") +
  labs(title= "2019 Predictions for Failed Food Inspections") +
  mapTheme()
```

The model is also useful in that it can be easily understood and explained relatively easily. The best outcome is one where those in power know how and why the model works. Unlike some "black box" algorithms whose inner workings are a mystery even to some of the people putting them into action, policymakers and even the public can understand this straightforward model.

# 7. Meeting the Use Case: Additional Design Elements

Several additional elements of this application help this model meet its use case, including tiered scheduling, a weather-specific inspection trigger mechanism, and 311 call inspection trigger mechanism.

#### Tiered Scheduling

Once this model produces a set of predictions for a given year, its work is not yet done. Having used its modeling feature to create a set of predictions, the application assigns teams of inspectors to groups of fishnet cells with proportional numbers of predicted inspectors. These teams can get to know an area and the local health factors that are relevant to restaurants in their zone. 

The scheduling element of this application prioritizes certain restaurants within each zone to receive earlier inspections based on their individual risk designation by the Chicago Health Department (the department already ranks restaurants as "high," "medium," and "low," risk). These assessments are used as priority tiers such that restaurants with higher Health Department risk rankings are prioritized within an inspection team's focus area.

#### Weather-specific Triggers

Weather has been shown to have measurable impacts on food inspection pass rates. Specifically, very hot weather produces higher rates of failures. Restaurants in Chicago should be expected to follow Department of Health guidelines regardless of the weather, including during periods of extremely hot weather. A three-day period of above average whether in Chicago during the summer triggers immediate inspections of high-risk restaurants if inspections are needed at any individual locations. 

#### 3-1-1 Call trigger Mechanism

Our application also makes the most of Chicago's 311 non-emergency City Services line with a mechanism to prioritize inspections in response to repeated calls. When excessive calls regarding a restaurant needing inspection are logged from different numbers (to prevent abuse of the mechanism) on multiple different days (to avoid over-penalization of specific events that result in multiple calls) over the course of a two-week period, an inspection is immediately triggered.

### Shortening the Feedback Loop

Our model, supplemented with the previously mentioned additional elements, is designed with the big-picture goal of "shortening the feedback loop" in mind. The feedback loop that exists in food inspection where restaurants follow or fail to follow health codes, are inspected, and take the result into account whether they choose to follow or fail to follow health codes. 

When restaurants choose unsafe practices, it is critical that this feedback loop is shortened so that there is as little chance as possible that unsafe practices lead to an outbreak such as the 2016 E. Coli outbreak in Chicago's Bridgeport neighborhood. This application works to shorten the food inspection feedback loop with solid foundation of failure prediction, enhanced by additional design elements that result in efficient inspections taking place where unsafe practices are more likely.

# 8. Improvement

There are several ways that the model - the foundation of the application - could be improved. First, predictions for a given year would likely be improved if they considered prospective inspection locations for that year. Ostensibly, the city has a database of locations it expects to inspect in a given year long before the year starts, and the use of this data could significantly improve the model. Additionally, more temporally-specific predictions could make scheduling inspectors more efficient. Predicting the failures expected for a quarter rather than a year would allow for better overall process. Finally, measures could be taken to ensure the model is not overly punitive of small and minority-owned businesses due to neighborhood-level factors out of the business owners' control. A good model of inspections must consider spatial factors, and while implicit bias will always be present, it is the job of the data scientist to discern and minimize its impact on the predictions.
